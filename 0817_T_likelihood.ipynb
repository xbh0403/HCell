{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week Aug 2 - Aug 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks this week:\n",
    "1. Go thorugh all parts of code carefully.\n",
    "2. Prototypes init as mean.\n",
    "3. More datasets.\n",
    "4. Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week Aug 17 - Aug 24\n",
    "\n",
    "Modify PL loss\n",
    "1. Normalize\n",
    "2. Student t distribution to replace distance for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import scanpy as sc\n",
    "from anndata.experimental.pytorch import AnnLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchnet.meter import ClassErrorMeter, AverageValueMeter\n",
    "# from torch_prototypes.modules import prototypical_network\n",
    "import prototypical_network\n",
    "from torch_prototypes.metrics import distortion, cost\n",
    "from torch_prototypes.metrics.distortion import DistortionLoss\n",
    "from  torch.distributions import multivariate_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import helper_fns\n",
    "import vanilla_vae\n",
    "\n",
    "import igraph as ig\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from anndata import AnnData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Loading, Label & Hierarchical encoding & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xbh0403/opt/anaconda3/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset // No problem\n",
    "# dataset = sc.read('./datasets/filtered_500_strict.h5ad')\n",
    "# dataset = sc.read('./datasets/filtered_data_500.h5ad')\n",
    "dataset = sc.read(\"/Volumes/SSD/global.h5ad\")\n",
    "# dataset = sc.read(\"../global.h5ad\")\n",
    "# Get all celltypes. // No problem\n",
    "list_celltypes = dataset.obs['Manually_curated_celltype'].unique().tolist()\n",
    "# These are the celltypes that we're going to remove. // No problem\n",
    "list_celltypes = list(filter(lambda x: x not in ['Mast cells', 'pDC','Progenitor', 'Erythroid', 'Megakaryocytes'], list_celltypes))\n",
    "# Remove the doublets // No problem\n",
    "list_filtered_celltypes = list(filter(lambda x: 'doublets' not in x, list_celltypes))\n",
    "# Remove celltypes from the dataset // No problem\n",
    "dataset = dataset[dataset.obs['Manually_curated_celltype'].isin(list_filtered_celltypes)]\n",
    "\n",
    "# Label encoder // No problem\n",
    "encoder_celltype = LabelEncoder()\n",
    "encoder_celltype.fit(dataset.obs['Manually_curated_celltype'])\n",
    "\n",
    "# Get the list of filtered celltypes // No problem\n",
    "list_ct = dataset.obs['Manually_curated_celltype'].unique().tolist()\n",
    "# Transform list of filtered celltypes to list of numbers // No problem\n",
    "list_num_ct = encoder_celltype.transform(list_ct)\n",
    "# These are higher level celltypes // No problem\n",
    "list_inner_nodes = ['Cross-tissue Immune Cell Atlas', 'B cell', 'Germinal center B cell', 'Myeloid', 'Dendritic cell',\n",
    "                    'Macrophages', 'Monocytes', 'T & Innate lymphoid cells', 'CD4', 'T Naive', 'CD8', \n",
    "                    'Tissue-resident memory T (Trm) cells', 'NK']\n",
    "all_nodes = list_ct + list_inner_nodes\n",
    "\n",
    "# The label encoder for inner nodes (High level celltype) // No problem\n",
    "encoder_celltype_inner = LabelEncoder()\n",
    "encoder_celltype_inner.fit(list_inner_nodes)\n",
    "\n",
    "# The transform function for both inner nodes and detailed celltypes // No problem\n",
    "def transfrom(x):\n",
    "    if x in list_inner_nodes:\n",
    "        return encoder_celltype_inner.transform([x])[0] + len(list_ct)\n",
    "    else:\n",
    "        return encoder_celltype.transform([x])[0]\n",
    "\n",
    "# Initialize the hierarchical tree // No problem\n",
    "g = ig.Graph()\n",
    "g.add_vertices(len(all_nodes))\n",
    "g.vs['name'] = np.append(encoder_celltype.inverse_transform(list(range(len(list_ct)))), encoder_celltype_inner.inverse_transform(list(range(len(list_inner_nodes)))))\n",
    "g.add_edges([(transfrom('Cross-tissue Immune Cell Atlas'), transfrom('B cell')),\n",
    "             (transfrom('Cross-tissue Immune Cell Atlas'), transfrom('Myeloid')),\n",
    "             (transfrom('Cross-tissue Immune Cell Atlas'), transfrom('T & Innate lymphoid cells'))])\n",
    "g.add_edges([(transfrom('B cell'), transfrom('ABCs')),\n",
    "             (transfrom('B cell'), transfrom('Germinal center B cell')),\n",
    "             (transfrom('B cell'), transfrom('Memory B cells')),\n",
    "             (transfrom('B cell'), transfrom('Naive B cells')),\n",
    "             (transfrom('B cell'), transfrom('Plasma cells')),\n",
    "             (transfrom('B cell'), transfrom('Plasmablasts')),\n",
    "             (transfrom('B cell'), transfrom('Pre-B')),\n",
    "             (transfrom('B cell'), transfrom('Pro-B'))])\n",
    "g.add_edges([(transfrom('Germinal center B cell'), transfrom('GC_B (I)')),\n",
    "             (transfrom('Germinal center B cell'), transfrom('GC_B (II)'))])\n",
    "g.add_edges([(transfrom('Myeloid'), transfrom('Cycling')),\n",
    "             (transfrom('Myeloid'), transfrom('Dendritic cell')),\n",
    "             (transfrom('Myeloid'), transfrom('Macrophages')),\n",
    "             (transfrom('Myeloid'), transfrom('Monocytes'))])\n",
    "g.add_edges([(transfrom('Dendritic cell'), transfrom('DC1')),\n",
    "             (transfrom('Dendritic cell'), transfrom('DC2')),\n",
    "             (transfrom('Dendritic cell'), transfrom('migDC'))])\n",
    "g.add_edges([(transfrom('Macrophages'), transfrom('Alveolar macrophages')),\n",
    "             (transfrom('Macrophages'), transfrom('Erythrophagocytic macrophages')),\n",
    "             (transfrom('Macrophages'), transfrom('Intermediate macrophages')),\n",
    "             (transfrom('Macrophages'), transfrom('Intestinal macrophages'))])\n",
    "g.add_edges([(transfrom('Monocytes'), transfrom('Classical monocytes')),\n",
    "             (transfrom('Monocytes'), transfrom('Nonclassical monocytes'))])\n",
    "g.add_edges([(transfrom('T & Innate lymphoid cells'), transfrom('CD4')),\n",
    "             (transfrom('T & Innate lymphoid cells'), transfrom('CD8')),\n",
    "             (transfrom('T & Innate lymphoid cells'), transfrom('Cycling T&NK')),\n",
    "             (transfrom('T & Innate lymphoid cells'), transfrom('ILC3')),\n",
    "             (transfrom('T & Innate lymphoid cells'), transfrom('NK')),\n",
    "             (transfrom('T & Innate lymphoid cells'), transfrom('T_CD4/CD8'))])\n",
    "g.add_edges([(transfrom('CD4'), transfrom('T Naive')),\n",
    "             (transfrom('CD4'), transfrom('Teffector/EM_CD4')),\n",
    "             (transfrom('CD4'), transfrom('Tfh')),\n",
    "             (transfrom('CD4'), transfrom('Tregs')),\n",
    "             (transfrom('CD4'), transfrom('Trm_Th1/Th17'))])\n",
    "g.add_edges([(transfrom('CD8'), transfrom('MAIT')),\n",
    "             (transfrom('CD8'), transfrom('Tem/emra_CD8')),\n",
    "             (transfrom('CD8'), transfrom('Tgd_CRTAM+')),\n",
    "             (transfrom('CD8'), transfrom('Tissue-resident memory T (Trm) cells')),\n",
    "             (transfrom('CD8'), transfrom('Tnaive/CM_CD8')),\n",
    "             (transfrom('CD8'), transfrom('Trm_Tgd'))])\n",
    "g.add_edges([(transfrom('NK'), transfrom('NK_CD16+')),\n",
    "             (transfrom('NK'), transfrom('NK_CD56bright_CD16-'))])\n",
    "g.add_edges([(transfrom('T Naive'), transfrom('Tnaive/CM_CD4')),\n",
    "             (transfrom('T Naive'), transfrom('Tnaive/CM_CD4_activated'))])\n",
    "g.add_edges([(transfrom('Tissue-resident memory T (Trm) cells'), transfrom('Trm/em_CD8')),\n",
    "             (transfrom('Tissue-resident memory T (Trm) cells'), transfrom('Trm_gut_CD8')),])\n",
    "\n",
    "# g.write('tree', format='gml')\n",
    "layout = g.layout(\"kamada_kawai\")\n",
    "ig.plot(g, layout=layout, vertex_label=g.vs[\"name\"], vertex_label_size=10, vertex_size=15, bbox=(1000, 1000), margin=100, vertex_color='white')\n",
    "\n",
    "# return the shortest distance between two nodes // No problem\n",
    "def get_shortest_dist(node_1, node_2, graph):\n",
    "    return len(graph.get_shortest_paths(node_1, node_2)[0])-1\n",
    " \n",
    "# Construct the distance matrix, init with 0 // No problem\n",
    "dist_df = pd.DataFrame(0, index=np.arange(len(list_num_ct)), columns=np.arange(len(list_num_ct)))\n",
    "for i in range(len(list_num_ct)):\n",
    "    for j in range(len(list_num_ct)):\n",
    "        dist_df.iloc[i, j]=get_shortest_dist(i, j, g)\n",
    "\n",
    "# Convert to tensor // No problem\n",
    "D = dist_df\n",
    "D = torch.tensor(D.values, dtype=float)\n",
    "\n",
    "# Train test split // No problem\n",
    "train_indices, test_indices, cv = helper_fns.costumized_train_test_split(dataset, cross_validation=False, k_fold=5)\n",
    "sc.pp.normalize_total(dataset, 1e4)\n",
    "sc.pp.log1p(dataset)\n",
    "pca = TruncatedSVD(n_components=128)\n",
    "pca.fit(dataset[train_indices].X)\n",
    "dataset_pca = AnnData(pca.transform(dataset.X))\n",
    "dataset_pca.obs = dataset.obs\n",
    "dataset = dataset_pca\n",
    "\n",
    "train_subsampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "test_subsampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Define data loaders for training and testing data in this fold\n",
    "encoders = {\n",
    "    'obs': {\n",
    "        'Manually_curated_celltype': encoder_celltype.transform\n",
    "    }\n",
    "}\n",
    "dataloader_training = AnnLoader(dataset, batch_size=512, convert=encoders, sampler=train_subsampler)\n",
    "dataloader_testing = AnnLoader(dataset, batch_size=512, convert=encoders, sampler=test_subsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of cells by cell type\n",
    "def get_num_by_ct(label, dataset):\n",
    "    return len(dataset.obs[dataset.obs['Manually_curated_celltype'] == label])\n",
    "\n",
    "weights = []\n",
    "for i in range(len(list_num_ct)):\n",
    "    weights.append(get_num_by_ct(encoder_celltype.inverse_transform([i])[0], dataset))\n",
    "weights = torch.tensor(weights, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch version of the 3 fully connected layers\n",
    "# No problem\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, mode, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# No problem\n",
    "class PL(nn.Module):\n",
    "    def __init__(self, centers, weights, vars):\n",
    "        super(PL, self).__init__()\n",
    "        self.centers = centers\n",
    "        self.weights = weights\n",
    "        self.vars = vars\n",
    "\n",
    "    def forward(self, mapping, labels):\n",
    "        # Find prototype by labels\n",
    "        targets = torch.index_select(self.centers, 0, labels)\n",
    "        # Sum the distance between each point and its prototype\n",
    "        weights = torch.index_select(self.weights, 0, labels)\n",
    "        log_vars = torch.log(torch.index_select(self.vars, 0, labels))\n",
    "        # dist = torch.norm(mapping - targets, dim=1)/weights\n",
    "        # return torch.sum(dist)/mapping.shape[0]\n",
    "        likelihood = -helper_fns.log_likelihood_student(mapping, targets, log_vars)/weights\n",
    "        return torch.sum(likelihood)/mapping.shape[0]\n",
    "        # return torch.sum(likelihood)/mapping.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mode, loss_mode, epochs=30, cuda=1):\n",
    "    if torch.cuda.is_available():\n",
    "        D_metric = D.cuda()\n",
    "    else:\n",
    "        D_metric = D\n",
    "    # A simple neural network no problem\n",
    "    if mode == 'Net':\n",
    "        if torch.cuda.is_available():\n",
    "            model = Net(mode, 128, 32, 37).cuda()\n",
    "        else:\n",
    "            model = Net(mode, 128, 32, 37)\n",
    "    # Learnt prototype & Simple neural network encoder no problem\n",
    "    elif mode == 'Proto_Net':\n",
    "        if torch.cuda.is_available():\n",
    "            model = Net(mode, 128, 32, 16).cuda()\n",
    "            centers = []\n",
    "            vars = []\n",
    "            for i in range(len(list_num_ct)):\n",
    "                out = model(torch.tensor(dataset[dataset.obs['Manually_curated_celltype'] == encoder_celltype.inverse_transform([i])[0]].X))\n",
    "                centers.append(np.array(torch.mean(out, dim=0)))\n",
    "                vars.append(np.array(torch.var(out, dim=0)))\n",
    "            centers = torch.tensor(centers, dtype=float).cuda()\n",
    "            vars = torch.tensor(vars, dtype=float).cuda()\n",
    "            model = prototypical_network.LearntPrototypes(model, n_prototypes= D.shape[0],\n",
    "                    prototypes=centers, vars=vars, embedding_dim=16, device='cuda').cuda()\n",
    "        else:\n",
    "            model = Net(mode, 128, 32, 16)\n",
    "            centers = []\n",
    "            vars = []\n",
    "            for i in range(len(list_num_ct)):\n",
    "                out = model(torch.tensor(dataset[dataset.obs['Manually_curated_celltype'] == encoder_celltype.inverse_transform([i])[0]].X))\n",
    "                centers.append(np.array(torch.mean(out, dim=0).detach()))\n",
    "                vars.append(np.array(torch.var(out, dim=0).detach()))\n",
    "            centers = torch.tensor(centers, dtype=float)\n",
    "            vars = torch.tensor(vars, dtype=float)\n",
    "            model = prototypical_network.LearntPrototypes(model, n_prototypes= D.shape[0],\n",
    "                    prototypes=centers, vars=vars, embedding_dim=16, device='cpu')\n",
    "    # Cross entropy loss no problem\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Distortion loss no problem\n",
    "    delta = DistortionLoss(D_metric)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    # Train & Test model, no problem\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        ER_meter = ClassErrorMeter(accuracy=False)\n",
    "\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        for batch in dataloader_training:\n",
    "            if torch.cuda.is_available():\n",
    "                x = batch.X.cuda()\n",
    "                y = batch.obs['Manually_curated_celltype'].type(torch.LongTensor).cuda()\n",
    "            else:\n",
    "                x = batch.X\n",
    "                y = batch.obs['Manually_curated_celltype'].type(torch.LongTensor)\n",
    "            y = y.squeeze()\n",
    "            y.long()\n",
    "            if mode == 'Net':\n",
    "                out = model(x)\n",
    "            elif mode == 'Proto_Net':\n",
    "                out, embeddings = model(x)\n",
    "            opt.zero_grad()\n",
    "            xe_loss = criterion(out, y)\n",
    "            loss = xe_loss\n",
    "            if 'pl' in loss_mode:\n",
    "                print(model.prototypes.shape)\n",
    "                print(model.vars.shape)\n",
    "                \n",
    "                pl_loss = PL(centers = model.prototypes.data, weights=weights, vars=model.vars)\n",
    "                pl_loss_ = pl_loss(embeddings, y)\n",
    "                loss = loss + pl_loss_\n",
    "            if 'disto' in loss_mode:\n",
    "                disto_loss = delta(model.prototypes)\n",
    "                loss = loss + disto_loss\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            pred = out.detach()\n",
    "            ER_meter.add(pred.cpu(),y.cpu())\n",
    "        vars = []\n",
    "        if mode == 'Proto_Net':\n",
    "            if torch.cuda.is_available():\n",
    "                for i in range(len(list_num_ct)):\n",
    "                    out, embeddings = model(torch.tensor(dataset[dataset.obs['Manually_curated_celltype'] == encoder_celltype.inverse_transform([i])[0]].X)).cpu()\n",
    "                    vars.append(np.array(torch.var(out, dim=0).detach().cpu()))\n",
    "                model.vars = torch.tensor(vars, dtype=float).cuda()\n",
    "            else:\n",
    "                for i in range(len(list_num_ct)):\n",
    "                    out, embeddings = model(torch.tensor(dataset[dataset.obs['Manually_curated_celltype'] == encoder_celltype.inverse_transform([i])[0]].X))\n",
    "                    # out = model(dataset.obs['Manually_curated_celltype'] == encoder_celltype.inverse_transform([i])[0])\n",
    "                    vars.append(np.array(torch.var(out, dim=0).detach()))\n",
    "                model.vars = torch.tensor(vars, dtype=float)\n",
    "        t1 = time.time()\n",
    "        \n",
    "        print('Train ER {:.2f}, time {:.1f}s'.format(ER_meter.value()[0], t1-t0))\n",
    "\n",
    "        model.eval()\n",
    "        ER_meter = ClassErrorMeter(accuracy=False)\n",
    "        t0 = time.time()\n",
    "        for batch in dataloader_testing:\n",
    "            if torch.cuda.is_available():\n",
    "                x = batch.X.cuda()\n",
    "                y = batch.obs['Manually_curated_celltype'].type(torch.LongTensor).cuda()\n",
    "            else:\n",
    "                x = batch.X\n",
    "                y = batch.obs['Manually_curated_celltype'].type(torch.LongTensor)\n",
    "            y = y.squeeze()\n",
    "            y.long()\n",
    "            if mode == 'Net':\n",
    "                with torch.no_grad():\n",
    "                    out = model(x)\n",
    "            elif mode == 'Proto_Net':\n",
    "                with torch.no_grad():\n",
    "                    out, embeddings = model(x)\n",
    "            pred = out.detach()\n",
    "            ER_meter.add(pred.cpu(),y)\n",
    "        t1 = time.time()\n",
    "        print('Test ER {:.2f}, time {:.1f}s'.format(ER_meter.value()[0], t1-t0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(mode, model):\n",
    "    y_test = dataset[test_indices].obs['Manually_curated_celltype']\n",
    "    if mode == 'Net':\n",
    "        if torch.cuda.is_available():\n",
    "            y_pred = model(torch.tensor(dataset[test_indices].X).cuda())\n",
    "        else:\n",
    "            y_pred = model(torch.tensor(dataset[test_indices].X))\n",
    "    elif mode == 'Proto_Net':\n",
    "        if torch.cuda.is_available():\n",
    "            y_pred, y_embeddings = model(torch.tensor(dataset[test_indices].X).cuda())\n",
    "        else:\n",
    "            y_pred, y_embeddings = model(torch.tensor(dataset[test_indices].X))\n",
    "    elif mode == 'VAE':\n",
    "        if torch.cuda.is_available():\n",
    "            y_pred, y_embeddings, x_hat, mean, log_var, decoder_mu, decoder_log_var = model(torch.tensor(dataset[test_indices].X).cuda())\n",
    "        else:\n",
    "            y_pred, y_embeddings, x_hat, mean, log_var, decoder_mu, decoder_log_var = model(torch.tensor(dataset[test_indices].X))\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    pred = encoder_celltype.inverse_transform(y_pred.argmax(axis=1))\n",
    "    cm=confusion_matrix(y_test, pred)\n",
    "    # Normalise\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=encoder_celltype.inverse_transform(range(len(dataset.obs['Manually_curated_celltype'].unique().tolist()))),\n",
    "                                        yticklabels=encoder_celltype.inverse_transform(range(len(dataset.obs['Manually_curated_celltype'].unique().tolist()))))\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_distance_matrix(mode, model):\n",
    "    y_test = encoder_celltype.transform(dataset[test_indices].obs['Manually_curated_celltype'])\n",
    "    if mode == 'Net':\n",
    "        if torch.cuda.is_available():\n",
    "            y_pred = model(torch.tensor(dataset[test_indices].X).cuda())\n",
    "        else:\n",
    "            y_pred = model(torch.tensor(dataset[test_indices].X))\n",
    "    elif mode == 'Proto_Net':\n",
    "        if torch.cuda.is_available():\n",
    "            y_pred, y_embeddings = model(torch.tensor(dataset[test_indices].X).cuda())\n",
    "        else:\n",
    "            y_pred, y_embeddings = model(torch.tensor(dataset[test_indices].X))\n",
    "    elif mode == 'VAE':\n",
    "        if torch.cuda.is_available():\n",
    "            y_pred, y_embeddings, x_hat, mean, log_var, decoder_mu, decoder_log_var = model(torch.tensor(dataset[test_indices].X).cuda())\n",
    "        else:\n",
    "            y_pred, y_embeddings, x_hat, mean, log_var, decoder_mu, decoder_log_var = model(torch.tensor(dataset[test_indices].X))\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    dist_list = []\n",
    "    for i in range(len(y_pred)):\n",
    "        distance = dist_df.iloc[y_pred[i], y_test[i]]\n",
    "        dist_list.append(distance)\n",
    "    print(np.mean(np.array(dist_list)))\n",
    "    sns.displot(dist_list)\n",
    "    plt.show(block=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train ER 17.36, time 5.5s\n",
      "Test ER 13.50, time 0.5s\n",
      "Epoch 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (37) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProto_Net\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdisto_pl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m train(mode\u001b[39m=\u001b[39;49mmode, loss_mode\u001b[39m=\u001b[39;49mloss_mode, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plot_confusion_matrix(mode, model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mmode\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mloss_mode\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb Cell 11\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mode, loss_mode, epochs, cuda)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpl\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m loss_mode:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     pl_loss \u001b[39m=\u001b[39m PL(centers \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mprototypes\u001b[39m.\u001b[39mdata, weights\u001b[39m=\u001b[39mweights, \u001b[39mvars\u001b[39m\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mvars)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     pl_loss_ \u001b[39m=\u001b[39m pl_loss(embeddings, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss \u001b[39m+\u001b[39m pl_loss_\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdisto\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m loss_mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb Cell 11\u001b[0m in \u001b[0;36mPL.forward\u001b[0;34m(self, mapping, labels)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m log_vars \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39mindex_select(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvars, \u001b[39m0\u001b[39m, labels))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# dist = torch.norm(mapping - targets, dim=1)/weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# return torch.sum(dist)/mapping.shape[0]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m likelihood \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mhelper_fns\u001b[39m.\u001b[39;49mlog_likelihood_student(mapping, targets, log_vars)\u001b[39m/\u001b[39mweights\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msum(likelihood)\u001b[39m/\u001b[39mmapping\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/HCell/helper_fns.py:72\u001b[0m, in \u001b[0;36mlog_likelihood_student\u001b[0;34m(x, mu, log_var, df)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_likelihood_student\u001b[39m(x, mu, log_var, df\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39m# df=mu.shape[0]-1\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     sigma \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39mexp(log_var))\n\u001b[0;32m---> 72\u001b[0m     dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mdistributions\u001b[39m.\u001b[39;49mStudentT(df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m     73\u001b[0m                                         loc\u001b[39m=\u001b[39;49mmu,\n\u001b[1;32m     74\u001b[0m                                         scale\u001b[39m=\u001b[39;49msigma)\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msum(dist\u001b[39m.\u001b[39mlog_prob(x), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/distributions/studentT.py:49\u001b[0m, in \u001b[0;36mStudentT.__init__\u001b[0;34m(self, df, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, df, loc\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m, scale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, validate_args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m broadcast_all(df, loc, scale)\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chi2 \u001b[39m=\u001b[39m Chi2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf)\n\u001b[1;32m     51\u001b[0m     batch_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39msize()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/distributions/utils.py:39\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     new_values \u001b[39m=\u001b[39m [v \u001b[39mif\u001b[39;00m is_tensor_like(v) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(v, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m     38\u001b[0m                   \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values]\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39m*\u001b[39;49mnew_values)\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbroadcast_tensors(\u001b[39m*\u001b[39mvalues)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (37) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "mode='Proto_Net'\n",
    "loss_mode='disto_pl'\n",
    "model = train(mode=mode, loss_mode=loss_mode, epochs=50)\n",
    "plot_confusion_matrix(mode, model)\n",
    "torch.save(model.state_dict(), './models/'+mode+'_'+loss_mode+'.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/HCell/0817_T_likelihood.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "out, embeddings = model(torch.tensor(dataset[test_indices].X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0aaeaca77e89efdee26218428d2dd31f57a40a6b69cea3d9bcbfda91b95b4233"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
