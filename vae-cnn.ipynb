{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import scanpy as sc\n",
    "from anndata.experimental.pytorch import AnnLoader\n",
    "\n",
    "import pretty_confusion_matrix as pcm\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchnet.meter import ClassErrorMeter, AverageValueMeter\n",
    "# from torch_prototypes.modules import prototypical_network\n",
    "import prototypical_network\n",
    "from torch_prototypes.metrics import distortion, cost\n",
    "from torch_prototypes.metrics.distortion import DistortionLoss\n",
    "from  torch.distributions import multivariate_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xbh04\\AppData\\Local\\Temp\\ipykernel_7024\\1807091802.py:13: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import Image, display\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Parameters-------------------\n",
    "embedding_dim = 3\n",
    "k_fold = 5\n",
    "cross_validation = False\n",
    "num_epoch=10\n",
    "batch_size=512\n",
    "feature_selection = True\n",
    "num_genes = 36601\n",
    "# --------------Plotting---------------------\n",
    "plot_loss = True\n",
    "plot_embedding_space = True\n",
    "plot_confusion_matrix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL(nn.Module):\n",
    "    def __init__(self, centers):\n",
    "        super(PL, self).__init__()\n",
    "        self.centers = centers\n",
    "\n",
    "    def forward(self, mapping, labels):\n",
    "        targets = torch.index_select(self.centers, 0, labels)\n",
    "        dist = torch.norm(mapping - targets, dim=1)\n",
    "        # print(dist[0])\n",
    "        dist = torch.sum(dist)\n",
    "        return dist/mapping.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('C:/Users/xbh04/Desktop/distance_matrix_bcell_ABCs.csv').iloc[:, 1:]\n",
    "D = torch.tensor(D.values, dtype=float)\n",
    "dataset = sc.read_h5ad(\"C:/Users/xbh04/Desktop/b-cells.h5ad\")\n",
    "dataset = dataset[dataset.obs['Manually_curated_celltype'] != 'MNP/B doublets']\n",
    "dataset = dataset[dataset.obs['Manually_curated_celltype'] != 'T/B doublets']\n",
    "dataset = dataset[dataset.obs['Manually_curated_celltype'] != 'ABCs']\n",
    "dataset_Pro_B = dataset[dataset.obs['Manually_curated_celltype'] == 'Pro-B']\n",
    "dataset = dataset[dataset.obs['Manually_curated_celltype'] != 'Pro-B']\n",
    "encoder_celltype = LabelEncoder()\n",
    "encoder_celltype.fit(dataset.obs['Manually_curated_celltype'])\n",
    "encoders = {\n",
    "    'obs': {\n",
    "        'Manually_curated_celltype': encoder_celltype.transform\n",
    "    }\n",
    "}\n",
    "\n",
    "indices_by_celltypes = {}\n",
    "train_indices, test_indices, cv = [], [], []\n",
    "for cell_type in dataset.obs['Manually_curated_celltype'].unique():\n",
    "    indices = np.where(dataset.obs['Manually_curated_celltype'] == cell_type)[0]\n",
    "    np.random.shuffle(indices)\n",
    "    indices_by_celltypes.update({cell_type: indices})\n",
    "    split = int(len(indices)/k_fold)\n",
    "    if cross_validation:\n",
    "        for i in range(k_fold):\n",
    "            temp = i*split\n",
    "            temp_test = list(indices[temp:temp+split])\n",
    "            temp_train = list(set(indices) - set(temp_test))\n",
    "            if cell_type != dataset.obs['Manually_curated_celltype'].unique()[0]:\n",
    "                cv[i].get(\"train\").extend(temp_train)\n",
    "                cv[i].get(\"test\").extend(temp_test)\n",
    "            else:\n",
    "                cv.append({\"train\":temp_train, \"test\": temp_test})\n",
    "    else:\n",
    "        test_indices.extend(indices[:split])\n",
    "        train_indices.extend(indices[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection by Scanpy\n",
    "def select_features(dataset_training):\n",
    "    print(\"feature_selection\")\n",
    "    dataset_training.var['mt'] = dataset_training.var_names.str.startswith('MT-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "    sc.pp.calculate_qc_metrics(dataset_training, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    sc_pp_train = sc.pp.filter_cells(dataset_training, min_genes=200, copy=True)\n",
    "    sc.pp.filter_genes(sc_pp_train, min_cells=3)\n",
    "    sc_pp_train = sc_pp_train[sc_pp_train.obs.n_genes_by_counts < 2500, :]\n",
    "    sc_pp_train = sc_pp_train[sc_pp_train.obs.pct_counts_mt < 5, :]\n",
    "    sc.pp.highly_variable_genes(sc_pp_train, n_top_genes=int(num_genes/4))\n",
    "    sc_pp_train = sc_pp_train[:, sc_pp_train.var.highly_variable]\n",
    "    return sc_pp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, h_dim=512, z_dim=3):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_genes, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(h_dim, z_dim)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, num_genes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae = VAE().to(device)\n",
    "model = prototypical_network.LearntPrototypes(model_vae.encoder, n_prototypes= D.shape[0],\n",
    "                                prototypes=None, embedding_dim=embedding_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_vae(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    # BCE = F.mse_loss(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (images, _) in enumerate(dataloader):\n",
    "        recon_images, mu, logvar = vae(images)\n",
    "        loss, bce, kld = loss_fn_vae(recon_images, images, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1, \n",
    "                                epochs, loss.data[0]/bs, bce.data[0]/bs, kld.data[0]/bs)\n",
    "        print(to_print)\n",
    "\n",
    "# notify to android when finished training\n",
    "notify(to_print, priority=1)\n",
    "\n",
    "torch.save(vae.state_dict(), 'vae.torch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2348cd6694856b0cd2d6b81b695ed315114d0b15be6e262935473537dcdc1e9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
